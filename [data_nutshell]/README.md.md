README.md

# data science in a nutshell

Hi everyone, I am a Udacity `Data Scientist Nanodegre` student, my name is Francis and I am come from China.

I this task, I am going to write a data science blog that can talk about some finding on data and illustrate how a data science can do.

I take the recommend data `stack overflow survey` as my analysis, maybe later I will add others, or you can submit your analysis along.

## / what will this series post tell you
Althrough this is a homework, but I am manage to give a meaningful introduction on how data science work in daily life. There main parts are:
- introduce data scientist working procedures (base on this part course notes)
- notice for data files
- all data science stage with codes

## / futher working plan and resouce recap
This post series will publish at Medium, and also at  github for all code and data.
- If you have question or finding err please reply at Medium
- Welcome any code corection and information related addon, please issue at git

## / working framework
My data science analysis framework is from `Udacity Data Sciencest Nanodegree`, here is a brief introduction, you can find it out at www.udacity.com or google if you want to learn more.

Data Science CRISP-DM (Cross Industry Process for Data Mining) Frame Work: 
1. Business Understanding
2. Data Understanding
3. Prepare Data
4. Data Modeling
5. Evaluate the Results
6. Deploy

## / content list
According to this Project Requement, and my plan, I am glad to take a try on dedicated blog writing. But for my tied schedule, ESL, and access Medium from China. I decide first to complete my project and update more post after my graduation.

Here is what I will provide for project1.
- a new git for project1(all code and copy of markdown files)
- README(this file) for introduction 
- Stackover flow survey data (case1)
    - 2/6 Data Understanding
    - 3/6 Prepare Data
    - 6/6 Deploy Data
- datafile(after cleaning)

## / further plan
As you can find, at this time, I am not going to use any Maching Learning tool to anayse the data. But with my data prepare. You can divide data set to what every you want and get some X,y for your hypothesis.

The original file is bigger than git, so I only update file after cleaning that will help you save time on data cleaning.
    